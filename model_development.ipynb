{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "HOUSING_TRAINING_DATA_PATH = os.path.join(\"data\", \"train.csv\")\n",
    "\n",
    "def load_csv_data(csv_path: str = HOUSING_TRAINING_DATA_PATH):\n",
    "    \"\"\" Load data from a csv file.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): The file path of the csv file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        df (pandas.DataFrame): A Pandas DataFrame object containing the data loaded from the input csv file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_data = load_csv_data()\n",
    "train_set, test_set = train_test_split(housing_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "housing_data.info(max_cols=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>255</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1067</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7837</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>639</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8777</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "254    255          20       RL         70.0     8400   Pave   NaN      Reg   \n",
       "1066  1067          60       RL         59.0     7837   Pave   NaN      IR1   \n",
       "638    639          30       RL         67.0     8777   Pave   NaN      Reg   \n",
       "799    800          50       RL         60.0     7200   Pave   NaN      Reg   \n",
       "380    381          50       RL         50.0     5000   Pave  Pave      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "254          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1066         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "638          Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "799          Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "380          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "254       6   2010        WD         Normal     145000  \n",
       "1066      5   2009        WD         Normal     178000  \n",
       "638       5   2008        WD         Normal      85000  \n",
       "799       6   2007        WD         Normal     175000  \n",
       "380       5   2010        WD         Normal     127000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Features\n",
    "Below are functions defined to carry out some of the desired feature engineering and transformations performed in the data analysis stage (see data_analysis.ipynb for more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def replace_na_with_none(df: pd.DataFrame, features):\n",
    "    \"\"\" Replace missing values with a 'none' string value.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The pandas dataframe object to replace missing values with 'none'.\n",
    "        features (array-like object): Array-like object containing the name feature of features to apply the transformation to. \n",
    "\n",
    "    Returns:\n",
    "        df (pandas.DataFrame): The pandas dataframe object with missing values replaces with 'none'.\n",
    "    \"\"\"\n",
    "    df[features].fillna(\"none\")\n",
    "    return df\n",
    "\n",
    "def createHasBsmtFullBath(df: pd.DataFrame):\n",
    "    \"\"\" Create the HasBsmtFullBath categorical attribute.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The pandas dataframe object to create the HasBsmtFullBath attribute for.\n",
    "\n",
    "    Returns:\n",
    "        df (pandas.DataFrame): The given pandas dataframe object with the new attribute.\n",
    "    \"\"\"\n",
    "    hasBsmtFullBath = np.zeros(df.shape[0])\n",
    "\n",
    "    for i, numberofBsmtFullBaths in enumerate(df[\"BsmtFullBath\"]):\n",
    "        if numberofBsmtFullBaths > 0:\n",
    "            hasBsmtFullBath[i] = 1\n",
    "\n",
    "    df[\"HasBsmtFullBath\"] = pd.Series(hasBsmtFullBath)\n",
    "    df = df.drop(columns=[\"BsmtFullBath\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def createHasHalfBath(df: pd.DataFrame):\n",
    "    \"\"\" Create the HasHalfBath categorical attribute.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The pandas dataframe object to create the HasHalfBath attribute for.\n",
    "\n",
    "    Returns:\n",
    "        df (pandas.DataFrame): The given pandas dataframe object with the new attribute.\n",
    "    \"\"\"\n",
    "    hasHalfBath = np.zeros(df.shape[0])\n",
    "\n",
    "    for i, numberofHalfBaths in enumerate(df[\"HalfBath\"]):\n",
    "        if numberofHalfBaths > 0:\n",
    "            hasHalfBath[i] = 1\n",
    "\n",
    "    df[\"HasHalfBath\"] = pd.Series(hasHalfBath)\n",
    "    df = df.drop(columns=[\"HalfBath\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def log_transform_features(df: pd.DataFrame, features):\n",
    "    \"\"\" Log transform the input features\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): A pandas dataframe object containing the features used for a model.\n",
    "        features (array-like object of strings): An array-like object containing the name of the features in df to be transformed. \n",
    "\n",
    "    Returns:\n",
    "        df (pandas.DataFrame): The pandas dataframe object containing the features used for the model and with the desired features log-transformed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        features_iterator = iter(features)\n",
    "        for feature in features_iterator:\n",
    "            df[feature] = np.log(df[feature] + 0.001)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except TypeError as error:\n",
    "        print(error)\n",
    "\n",
    "def apply_custom_transformations(df: pd.DataFrame, categorical_attributes, continuous_attributes, target_attribute: str):\n",
    "    \"\"\" Apply the feature helper functions to a given pandas dataframe object to apply the custom data transformations.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): A pandas dataframe object contiaining the dataset to be modelled.\n",
    "        categorical_attributes: An array-like object containing the names of the desired categorical attributes.\n",
    "        continuous attributes: An array-like object containing the names of the desired continuous attributes.\n",
    "        target_attribute (string): The name of the target attribute.\n",
    "\n",
    "    Returns:\n",
    "        (X, y): A tuple of the transformed features X and the transformed target y.\n",
    "    \"\"\"\n",
    "    partially_prepped_set = replace_na_with_none(df, categorical_attributes)\n",
    "    partially_prepped_set = createHasBsmtFullBath(partially_prepped_set)\n",
    "    partially_prepped_set = createHasHalfBath(partially_prepped_set)\n",
    "    partially_prepped_set = log_transform_features(partially_prepped_set, continuous_attributes)\n",
    "\n",
    "    X = partially_prepped_set.drop(columns=[target_attribute])\n",
    "    y = partially_prepped_set[target_attribute]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for Data Preprocessing \n",
    "First, the helper functions are applied to perform initial feature engineering and data preprocessing. Then the data is passed through a scikit-learn pipeline for further preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 56)\n",
      "(292, 56)\n"
     ]
    }
   ],
   "source": [
    "continuous_data_attributes = [\n",
    "    \"SalePrice\",\n",
    "    \"LotFrontage\",\n",
    "    \"MasVnrArea\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"1stFlrSF\",\n",
    "    \"2ndFlrSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"GarageArea\"\n",
    "]\n",
    "\n",
    "continuous_features = [\n",
    "    \"LotFrontage\",\n",
    "    \"MasVnrArea\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"1stFlrSF\",\n",
    "    \"2ndFlrSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"GarageArea\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"OverallQual\",\n",
    "    \"OverallCond\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"FullBath\",\n",
    "    \"HalfBath\",\n",
    "    \"TotRmsAbvGrd\",\n",
    "    \"Fireplaces\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageCars\",\n",
    "    \"GarageType\",\n",
    "    \"GarageFinish\",\n",
    "    \"GarageQual\",\n",
    "    \"GarageCond\",\n",
    "    \"PavedDrive\",\n",
    "    \"Street\",\n",
    "    \"Alley\",\n",
    "    \"LotShape\",\n",
    "    \"LandContour\",\n",
    "    \"LotConfig\",\n",
    "    \"LandSlope\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"ExterQual\",\n",
    "    \"ExterCond\",\n",
    "    \"Foundation\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtCond\",\n",
    "    \"BsmtExposure\",\n",
    "    \"BsmtFinType1\",\n",
    "    \"BsmtFinType2\",\n",
    "    \"Heating\",\n",
    "    \"HeatingQC\",\n",
    "    \"CentralAir\",\n",
    "    \"Electrical\",\n",
    "    \"PoolQC\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\"\n",
    "]\n",
    "\n",
    "partially_prepped_categorical_features = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"OverallQual\",\n",
    "    \"OverallCond\",\n",
    "    \"HasBsmtFullBath\",\n",
    "    \"FullBath\",\n",
    "    \"HasHalfBath\",\n",
    "    \"TotRmsAbvGrd\",\n",
    "    \"Fireplaces\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageCars\",\n",
    "    \"GarageType\",\n",
    "    \"GarageFinish\",\n",
    "    \"GarageQual\",\n",
    "    \"GarageCond\",\n",
    "    \"PavedDrive\",\n",
    "    \"Street\",\n",
    "    \"Alley\",\n",
    "    \"LotShape\",\n",
    "    \"LandContour\",\n",
    "    \"LotConfig\",\n",
    "    \"LandSlope\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"ExterQual\",\n",
    "    \"ExterCond\",\n",
    "    \"Foundation\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtCond\",\n",
    "    \"BsmtExposure\",\n",
    "    \"BsmtFinType1\",\n",
    "    \"BsmtFinType2\",\n",
    "    \"Heating\",\n",
    "    \"HeatingQC\",\n",
    "    \"CentralAir\",\n",
    "    \"Electrical\",\n",
    "    \"PoolQC\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\"\n",
    "]\n",
    "\n",
    "attributes = continuous_data_attributes + categorical_features\n",
    "train_set = train_set[attributes]\n",
    "test_set = test_set[attributes]\n",
    "\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 55)\n",
      "(1168,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = apply_custom_transformations(train_set, categorical_features, continuous_data_attributes, \"SalePrice\")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "iterative_imputer = IterativeImputer(random_state=42)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "feature_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "continuous_pipeline = Pipeline([\n",
    "    (\"min_max_scaler\", min_max_scaler),\n",
    "    (\"iterative_imputer\", iterative_imputer)\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"feature_encoder\", feature_encoder)\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"continuous\", continuous_pipeline, continuous_features),\n",
    "    (\"categorical\", categorical_pipeline, partially_prepped_categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1168, 316)\n",
      "(1168, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "y_train_prepared = iterative_imputer.fit_transform(y_train.to_numpy().reshape(-1, 1))\n",
    "\n",
    "print(type(X_train_prepared))\n",
    "print(type(y_train_prepared))\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model - Mean Prediction\n",
    "A naive model that predicts the mean will be used as the baseline model to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292, 55)\n",
      "(292,)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.4319878652441567\n",
      "R-Squared Coefficient: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_test, y_test = apply_custom_transformations(test_set, categorical_features, continuous_data_attributes, \"SalePrice\")\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "y_test_prepared = iterative_imputer.transform(y_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "baseline_predictions = np.array([y_test_prepared.mean() for i in range(y_test_prepared.shape[0])]).reshape(-1, 1)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_test_prepared, baseline_predictions))\n",
    "r2 = r2_score(y_test_prepared, baseline_predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {error}\")\n",
    "print(f\"R-Squared Coefficient: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for displaying Root Mean-squared Error scores from Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cv_scores(scores):\n",
    "    \"\"\" Display the error scores from cross validation and basic statistics.\n",
    "\n",
    "    Args:\n",
    "        scores (array-like): An array-like object containing the error scores from cross validation.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(f\"Scores: {scores}\")\n",
    "    print(f\"Mean: {scores.mean()}\")\n",
    "    print(f\"Standard Deviation: {scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development - Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.10065524185825711\n",
      "R-Squared Coefficient: 0.9335398438989518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "ridge_reg = Ridge(random_state=42)\n",
    "ridge_reg.fit(X_train_prepared, y_train_prepared)\n",
    "ridge_reg_preds = ridge_reg.predict(X_train_prepared)\n",
    "\n",
    "ridge_reg_error = np.sqrt(mean_squared_error(y_train_prepared, ridge_reg_preds))\n",
    "ridge_reg_r2 = r2_score(y_train_prepared, ridge_reg_preds)\n",
    "print(f\"Root Mean Squared Error: {ridge_reg_error}\")\n",
    "print(f\"R-Squared Coefficient: {ridge_reg_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.11561654 0.15405244 0.11995224 0.18179933 0.19491573 0.152178\n",
      " 0.13768553 0.12024211 0.13452398 0.09531781]\n",
      "Mean: 0.14062837082965374\n",
      "Standard Deviation: 0.029194910681579544\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.88629525 0.87008705 0.89828613 0.77786317 0.73886865 0.89978099\n",
      " 0.86667763 0.90267376 0.85112127 0.9328614 ]\n",
      "Mean: 0.8624515304417212\n",
      "Standard Deviation: 0.05696837958313602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "ridge_reg_cv_mse_scores = cross_val_score(ridge_reg, X_train_prepared, y_train_prepared, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "ridge_reg_cv_rmse_scores = np.sqrt(abs(ridge_reg_cv_mse_scores))\n",
    "ridge_reg_cv_r2_scores = cross_val_score(ridge_reg, X_train_prepared, y_train_prepared, cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(ridge_reg_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(ridge_reg_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.10438714257352695\n",
      "R-Squared Coefficient: 0.9285203227513172\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "linear_svm = LinearSVR(random_state=42, dual=False, loss=\"squared_epsilon_insensitive\")\n",
    "linear_svm.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "linear_svm_preds = linear_svm.predict(X_train_prepared)\n",
    "\n",
    "linear_svm_error = np.sqrt(mean_squared_error(y_train_prepared.flatten(), linear_svm_preds))\n",
    "linear_svm_r2 = r2_score(y_train_prepared.flatten(), linear_svm_preds)\n",
    "print(f\"Root Mean Squared Error: {linear_svm_error}\")\n",
    "print(f\"R-Squared Coefficient: {linear_svm_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.14024312 0.17421172 0.12045698 0.19440458 0.17407939 0.16050042\n",
      " 0.14531016 0.13203258 0.16128425 0.11294856]\n",
      "Mean: 0.1515471758352345\n",
      "Standard Deviation: 0.02457044294615533\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.83269776 0.83386159 0.89742834 0.74599106 0.79171404 0.88851955\n",
      " 0.85150275 0.88265112 0.78599832 0.9057274 ]\n",
      "Mean: 0.8416091942315299\n",
      "Standard Deviation: 0.05106288917922683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "linear_svm_cv_mse_scores = cross_val_score(linear_svm, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "linear_svm_cv_rmse_scores = np.sqrt(abs(linear_svm_cv_mse_scores))\n",
    "linear_svm_cv_r2_scores = cross_val_score(linear_svm, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(linear_svm_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(linear_svm_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.08495056077503223\n",
      "R-Squared Coefficient: 0.9526607837206451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "rbf_svm = SVR(kernel=\"rbf\")\n",
    "rbf_svm.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "rbf_svm_preds = rbf_svm.predict(X_train_prepared)\n",
    "\n",
    "rbf_svm_error = np.sqrt(mean_squared_error(y_train_prepared.flatten(), rbf_svm_preds))\n",
    "rbf_svm_r2 = r2_score(y_train_prepared.flatten(), rbf_svm_preds)\n",
    "print(f\"Root Mean Squared Error: {rbf_svm_error}\")\n",
    "print(f\"R-Squared Coefficient: {rbf_svm_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.13346413 0.15624561 0.13404105 0.1680172  0.14894035 0.18010465\n",
      " 0.15231971 0.13369679 0.13663173 0.12698797]\n",
      "Mean: 0.14704492024763402\n",
      "Standard Deviation: 0.01640511337532559\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.84848076 0.86636171 0.87298964 0.81026672 0.84752803 0.85962292\n",
      " 0.83683063 0.87967421 0.8464194  0.88083483]\n",
      "Mean: 0.854900885070531\n",
      "Standard Deviation: 0.020623757369495222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "rbf_svm_cv_mse_scores = cross_val_score(rbf_svm, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "rbf_svm_cv_rmse_scores = np.sqrt(abs(rbf_svm_cv_mse_scores))\n",
    "rbf_svm_cv_r2_scores = cross_val_score(rbf_svm, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(rbf_svm_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(rbf_svm_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.05702459738550259\n",
      "R-Squared Coefficient: 0.9786689114316451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "rf_preds = rf.predict(X_train_prepared)\n",
    "\n",
    "rf_error = np.sqrt(mean_squared_error(y_train_prepared.flatten(), rf_preds))\n",
    "rf_r2 = r2_score(y_train_prepared.flatten(), rf_preds)\n",
    "print(f\"Root Mean Squared Error: {rf_error}\")\n",
    "print(f\"R-Squared Coefficient: {rf_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.10987647 0.17139176 0.13087552 0.20228661 0.16377821 0.19708108\n",
      " 0.16151663 0.15022191 0.13625269 0.12303185]\n",
      "Mean: 0.1546312706178065\n",
      "Standard Deviation: 0.028996676669735134\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.8973053  0.83919662 0.87891781 0.7249762  0.81563542 0.83191219\n",
      " 0.81653176 0.84809107 0.84727034 0.88814402]\n",
      "Mean: 0.8387980725346523\n",
      "Standard Deviation: 0.04654152986986867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "rf_cv_mse_scores = cross_val_score(rf, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "rf_cv_rmse_scores = np.sqrt(abs(rf_cv_mse_scores))\n",
    "rf_cv_r2_scores = cross_val_score(rf, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(rf_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(rf_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting - Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.0892122074980093\n",
      "R-Squared Coefficient: 0.9477919905269637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(random_state=42)\n",
    "gbrt.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "gbrt_preds = gbrt.predict(X_train_prepared)\n",
    "\n",
    "gbrt_error = np.sqrt(mean_squared_error( y_train_prepared.flatten(), gbrt_preds))\n",
    "gbrt_r2 = r2_score( y_train_prepared.flatten(), gbrt_preds)\n",
    "print(f\"Root Mean Squared Error: {gbrt_error}\")\n",
    "print(f\"R-Squared Coefficient: {gbrt_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.09281897 0.15672893 0.13148528 0.18663962 0.14216594 0.17078338\n",
      " 0.14047582 0.12292933 0.13380592 0.10752161]\n",
      "Mean: 0.1385354793564828\n",
      "Standard Deviation: 0.02658828134357971\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.92671549 0.86553365 0.87778691 0.76587722 0.86108269 0.87377727\n",
      " 0.86121913 0.89827498 0.8527064  0.91456898]\n",
      "Mean: 0.8697542710877546\n",
      "Standard Deviation: 0.041706123326991154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "gbrt_cv_mse_scores = cross_val_score(gbrt, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "gbrt_cv_rmse_scores = np.sqrt(abs(gbrt_cv_mse_scores))\n",
    "gbrt_cv_r2_scores = cross_val_score(gbrt, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(gbrt_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(gbrt_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\.conda\\envs\\ames_housing_prediction\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.014505439556389013\n",
      "R-Squared Coefficient: 0.9986197735334046\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "xgb_reg.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "xgb_reg_preds = xgb_reg.predict(X_train_prepared)\n",
    "\n",
    "xgb_reg_error = np.sqrt(mean_squared_error(y_train_prepared.flatten(), xgb_reg_preds))\n",
    "xgb_reg_r2 = r2_score(y_train_prepared.flatten(), xgb_reg_preds)\n",
    "print(f\"Root Mean Squared Error: {xgb_reg_error}\")\n",
    "print(f\"R-Squared Coefficient: {xgb_reg_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.10489083 0.17869019 0.13695984 0.18394633 0.13207265 0.18568311\n",
      " 0.14447382 0.13408719 0.12790194 0.11546787]\n",
      "Mean: 0.14441737623442968\n",
      "Standard Deviation: 0.02725422706467584\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.90641339 0.82520995 0.86739805 0.77258545 0.88010778 0.85079232\n",
      " 0.8532072  0.87897047 0.86541784 0.901475  ]\n",
      "Mean: 0.8601577451810624\n",
      "Standard Deviation: 0.0370202500911056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "xgb_reg_cv_mse_scores = cross_val_score(xgb_reg, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "xgb_reg_cv_rmse_scores = np.sqrt(abs(xgb_reg_cv_mse_scores))\n",
    "xgb_reg_cv_r2_scores = cross_val_score(xgb_reg, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(xgb_reg_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(xgb_reg_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Candidate Models\n",
    "Based on initial model exploration, below are the top 3 candidate models to further fine-tune and compare results:\n",
    "- Gradient Boosting Regression\n",
    "- XGBoost\n",
    "- Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development - Fine-tuning/Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramater Optimization - Gradient Boosting Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\.conda\\envs\\ames_housing_prediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [-8.04756139e+94 -1.35718662e-01 -1.38723404e-01 -2.00335429e-01\n",
      " -1.58095206e-01 -2.70319514e-01 -2.37975084e-01 -2.25850922e-01\n",
      "             nan -1.40896308e-01             nan -1.42011853e-01\n",
      " -2.28634711e-01 -1.63877377e-01 -1.35679329e-01 -1.55212355e-01\n",
      " -1.52252861e-01 -1.39094892e-01 -1.58386390e-01             nan\n",
      " -1.63877377e-01 -1.38782817e-01 -1.36913324e-01 -1.97237797e-01\n",
      " -2.56598726e-01 -1.51590156e-01 -1.33465895e-01 -1.60503555e-01\n",
      "             nan             nan             nan -2.12018376e-01\n",
      " -1.43152682e-01 -4.93677210e-01 -3.03147097e-01 -8.04756139e+94\n",
      "             nan -1.45956057e-01 -2.17847124e-01 -2.29812528e-01\n",
      " -6.17937362e+94 -1.52120968e-01 -8.06255317e+94 -2.25850922e-01\n",
      " -1.57321604e-01 -3.35846530e-01 -2.48358709e-01 -1.89760734e-01\n",
      " -1.79055710e-01             nan -2.04835614e-01 -1.78989581e-01\n",
      " -1.33781275e-01 -1.97779281e-01 -1.38590842e-01 -2.47522916e-01\n",
      " -2.48385200e-01 -2.52380273e-01 -1.58095206e-01             nan\n",
      " -3.69856470e-01 -1.39159692e-01             nan -1.44467420e-01\n",
      "             nan             nan             nan -2.12018375e-01\n",
      " -2.47180930e-01             nan -1.62618603e-01 -2.59024408e-01\n",
      " -3.09200130e-01 -2.36376346e-01 -1.39180533e-01             nan\n",
      " -1.36588136e-01 -1.40080205e-01 -1.84015702e-01 -2.56500579e-01\n",
      "             nan -1.35340629e-01 -1.45956057e-01 -1.40796297e-01\n",
      " -2.99739663e-01             nan             nan -2.28634711e-01\n",
      " -1.44996003e-01 -1.52038787e-01 -1.36488119e-01 -3.64276251e-01\n",
      " -2.99739663e-01 -8.15262961e+94 -1.66506737e-01 -1.85643381e-01\n",
      "             nan -1.48626967e-01 -3.66408392e-01 -2.03155310e-01\n",
      " -2.49889180e-01 -1.88667209e-01             nan -6.33868882e+94\n",
      " -8.45772882e+94 -1.31845840e-01             nan -1.56727267e-01\n",
      " -2.28749637e-01 -1.66862243e-01 -2.57955949e-01 -1.58386390e-01\n",
      " -1.35354633e-01 -1.37930771e-01 -1.36920702e-01 -1.40796297e-01\n",
      " -2.58671792e-01 -1.66862243e-01 -1.32453802e-01 -2.24299212e-01\n",
      " -1.40808263e-01 -1.88667209e-01 -2.86869398e-01 -2.60788196e-01\n",
      "             nan             nan -1.40635239e-01 -2.17959537e-01\n",
      " -3.35846530e-01 -1.74219422e-01             nan -2.17959537e-01\n",
      " -1.44467420e-01 -1.69629462e-01 -1.97246648e-01 -2.58671792e-01\n",
      " -1.44147166e-01 -3.64306700e-01 -1.54164547e-01 -3.09200130e-01\n",
      " -1.85643381e-01 -1.59790938e-01 -3.35103210e-01 -1.97246648e-01\n",
      " -1.60532370e-01 -1.33465895e-01 -1.52120968e-01             nan\n",
      " -1.33076634e-01 -1.79055710e-01             nan -8.89825184e+94\n",
      " -1.97237797e-01             nan -2.39301360e-01 -3.34366086e-01\n",
      " -1.37752799e-01 -1.35793499e-01 -1.52038787e-01 -2.49337032e-01\n",
      " -1.48626967e-01 -2.68193881e-01 -7.94593285e+94 -2.48358709e-01\n",
      " -1.44839109e-01 -1.42173928e-01             nan -2.96045627e-01\n",
      " -1.36821717e-01 -1.33329213e-01 -1.40704407e-01 -1.40080205e-01\n",
      " -1.59470859e-01 -3.76729817e-01             nan -1.35398128e-01\n",
      "             nan -1.90573566e-01 -1.64886285e-01 -1.79541664e-01\n",
      " -4.93206546e-01 -1.38026607e-01 -3.73238272e-01 -2.24127600e-01\n",
      " -3.84337190e-01 -3.76570387e-01 -2.12018377e-01             nan\n",
      " -8.15262961e+94 -1.62618603e-01 -1.85643381e-01 -1.39847747e-01\n",
      " -3.97097446e-01 -2.17847124e-01 -2.68193881e-01 -1.48186013e-01\n",
      " -1.55212355e-01 -8.14273014e+94 -1.79055710e-01 -1.47575048e-01\n",
      " -1.40796297e-01 -3.08115953e-01 -1.37837656e-01 -3.66478883e-01\n",
      "             nan -1.39005255e-01 -8.14273014e+94 -2.56598726e-01\n",
      "             nan -6.09903474e+94             nan -3.76848039e-01\n",
      " -1.40634476e-01 -1.55217067e-01 -2.96045627e-01 -6.33868882e+94\n",
      " -1.90539158e-01 -2.12018377e-01 -1.45393438e-01 -3.35846530e-01\n",
      " -1.40917263e-01             nan -3.76570387e-01 -2.52380273e-01\n",
      " -1.57321604e-01 -1.32453802e-01 -1.38050806e-01 -1.41809582e-01\n",
      " -3.68346862e-01 -1.34406652e-01 -1.41580627e-01 -1.80161120e-01\n",
      " -2.52380273e-01 -1.97246648e-01 -1.66506737e-01 -1.35718662e-01\n",
      "             nan -1.92974174e-01 -7.87180373e+94 -2.31630119e-01\n",
      "             nan -1.79541664e-01 -3.08115953e-01 -1.42641176e-01\n",
      " -1.84015702e-01 -2.91632063e-01 -1.39354773e-01 -1.35215016e-01\n",
      " -1.80860500e-01             nan -8.19722554e+94 -4.04460993e-01\n",
      "             nan -1.79055710e-01             nan -1.90233836e-01\n",
      " -1.38695975e-01 -1.60532370e-01 -2.17695013e-01 -7.94593285e+94\n",
      "             nan -2.24989165e-01 -2.97847287e-01 -1.72370894e-01\n",
      "             nan -1.39695849e-01 -1.55217067e-01             nan\n",
      " -1.88667209e-01 -1.39799704e-01 -1.45393438e-01 -1.72370894e-01\n",
      " -2.89424617e-01 -1.39048655e-01 -1.97800502e-01 -2.17695013e-01\n",
      "             nan -3.64276251e-01 -6.17937362e+94 -1.43255163e-01\n",
      " -1.49627077e-01 -1.39039441e-01 -1.44839109e-01 -2.36390075e-01\n",
      " -1.48186013e-01 -3.66408392e-01 -1.32774914e-01 -1.92282177e-01\n",
      " -1.72370894e-01 -1.36926293e-01 -1.38987459e-01 -1.48442660e-01\n",
      " -2.72805928e-01 -1.60532370e-01 -2.94751774e-01 -2.96250388e-01\n",
      " -1.52252861e-01 -1.89760734e-01 -1.43591601e-01 -3.71912645e-01\n",
      " -4.93677210e-01 -1.35981237e-01             nan -8.50889653e+94\n",
      " -1.38980808e-01 -2.68266411e-01 -1.37930771e-01             nan\n",
      " -1.92974174e-01 -1.48442660e-01 -1.39354888e-01 -1.38240898e-01\n",
      "             nan -2.57955949e-01 -2.56500579e-01             nan\n",
      " -2.39087151e-01 -8.18464499e+94 -1.46430917e-01 -1.49627077e-01\n",
      " -1.41809582e-01 -3.76729817e-01 -3.35103210e-01 -1.40796297e-01\n",
      " -2.94751774e-01             nan -1.38365037e-01             nan\n",
      " -2.66018153e-01 -6.33868882e+94             nan -1.40796297e-01\n",
      " -2.39087151e-01             nan -4.87540226e-01 -2.03155310e-01\n",
      " -2.58671792e-01 -1.49439251e-01 -3.84337190e-01 -1.97800502e-01\n",
      " -1.89760734e-01 -1.38365037e-01 -1.44126588e-01 -1.32453802e-01\n",
      " -1.39722393e-01 -2.48358709e-01 -1.53996557e-01 -1.40796297e-01\n",
      " -3.10217895e-01             nan -1.66506737e-01 -2.17695013e-01\n",
      " -3.65378807e-01             nan -1.60532370e-01 -1.64886285e-01\n",
      "             nan             nan -1.79055710e-01 -1.59790938e-01\n",
      " -1.33076634e-01 -1.37752799e-01 -1.55217067e-01 -1.33329213e-01\n",
      " -1.34376856e-01 -2.24299212e-01             nan -2.28236543e-01\n",
      " -2.09639342e-01 -2.85738467e-01 -1.42011853e-01 -1.62618603e-01\n",
      " -1.37497058e-01 -1.96811437e-01 -3.01915552e-01 -3.76570387e-01\n",
      " -2.03155310e-01 -2.49519976e-01 -1.36747156e-01 -1.42641176e-01\n",
      "             nan -1.42641176e-01 -5.39014291e-01 -1.36913324e-01\n",
      " -1.43479095e-01 -1.57321604e-01 -3.03150675e-01 -1.40796297e-01\n",
      " -1.45393438e-01             nan -1.58095206e-01             nan\n",
      "             nan -1.59470859e-01 -1.49439251e-01             nan\n",
      " -1.35793499e-01 -2.09639373e-01 -1.41310211e-01 -1.96598331e-01\n",
      " -2.72805928e-01 -1.66506737e-01 -2.99468477e-01 -1.36920702e-01\n",
      " -2.49337032e-01 -2.70319514e-01 -3.35103210e-01 -2.28664151e-01\n",
      " -2.28633537e-01 -2.72805928e-01 -1.38192002e-01 -3.69894332e-01\n",
      "             nan             nan -1.34406652e-01 -1.97246514e-01\n",
      " -1.38590842e-01 -2.36376346e-01             nan -1.35340629e-01\n",
      " -1.59790938e-01 -2.59024408e-01 -1.54164547e-01 -1.85643381e-01\n",
      " -1.62618603e-01             nan -1.39005255e-01 -1.33686838e-01\n",
      " -5.38791099e-01 -1.35665064e-01 -2.17959537e-01 -1.54164547e-01\n",
      " -1.33259553e-01 -2.17695013e-01 -2.58596764e-01 -1.35948411e-01\n",
      " -2.28236543e-01 -1.40837793e-01 -1.43255163e-01 -2.96045627e-01\n",
      " -2.09639342e-01             nan             nan -1.48626967e-01\n",
      " -1.39354888e-01 -1.52252861e-01 -3.66397643e-01 -2.36390075e-01\n",
      " -1.41809582e-01             nan -1.35793499e-01 -2.02273777e-01\n",
      " -1.41507091e-01 -1.43255163e-01 -2.04835614e-01 -2.02273777e-01\n",
      " -4.25409971e-01 -1.37549928e-01 -1.44126588e-01             nan\n",
      " -2.17695013e-01 -2.30094995e-01 -2.46966622e-01 -1.35398128e-01\n",
      " -1.94510459e-01             nan -3.34366086e-01             nan\n",
      "             nan -1.59790938e-01 -1.43152682e-01 -1.66862243e-01\n",
      " -1.36693979e-01 -1.79541664e-01 -2.12018376e-01 -2.28634711e-01\n",
      " -6.17937362e+94 -2.48358435e-01 -1.40179444e-01             nan\n",
      " -1.39799704e-01 -2.39301360e-01             nan -3.68346862e-01\n",
      " -1.58095206e-01             nan -2.40404171e-01             nan\n",
      " -2.97858994e-01 -3.84337190e-01 -1.35679329e-01 -2.12018376e-01\n",
      " -2.68266411e-01 -1.60503555e-01             nan -1.48442660e-01\n",
      " -2.66018440e-01 -1.33329213e-01 -1.43255163e-01 -1.78989581e-01]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "gbrt = GradientBoostingRegressor(random_state=42)\n",
    "param_distributions = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"n_estimators\": [100, 500, 1000, 1500, 2000],\n",
    "    \"max_depth\": [1, 2, 3, 4],\n",
    "    \"max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "    \"subsample\": [0.5, 0.75, 1]\n",
    "}\n",
    "gbrt_reg = RandomizedSearchCV(gbrt, param_distributions=param_distributions, n_iter=500, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, random_state=42)\n",
    "gbrt_search = gbrt_reg.fit(X_train_prepared, y_train_prepared.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative RMSE: -0.06654574787561507\n",
      "Parameters for the best estimator: \n",
      "{'subsample': 0.5, 'n_estimators': 2000, 'max_leaf_nodes': 10, 'max_depth': 3, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Negative RMSE: {gbrt_search.score(X_train_prepared, y_train_prepared.flatten())}\")\n",
    "print(f\"Parameters for the best estimator: \\n{gbrt_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.06654574787561507\n",
      "R-Squared Coefficient: 0.9709511339423144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "gbrt_optimized = GradientBoostingRegressor(\n",
    "    random_state=42, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=3,\n",
    "    max_leaf_nodes=10, \n",
    "    n_estimators=2000,\n",
    "    subsample=0.5\n",
    ")\n",
    "gbrt_optimized.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "gbrt_optimized_preds = gbrt_optimized.predict(X_train_prepared)\n",
    "\n",
    "\n",
    "gbrt_optimized_error = np.sqrt(mean_squared_error( y_train_prepared.flatten(), gbrt_optimized_preds))\n",
    "gbrt_optimized_r2 = r2_score( y_train_prepared.flatten(), gbrt_optimized_preds)\n",
    "print(f\"Root Mean Squared Error: {gbrt_optimized_error}\")\n",
    "print(f\"R-Squared Coefficient: {gbrt_optimized_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.09092648 0.14380362 0.11859793 0.18425085 0.13426207 0.16034311\n",
      " 0.12992157 0.11232161 0.1266227  0.09336753]\n",
      "Mean: 0.12944174783251697\n",
      "Standard Deviation: 0.027188363427820276\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.92967343 0.88679778 0.90056995 0.77183185 0.87609982 0.88873797\n",
      " 0.88128955 0.91507347 0.86809647 0.93558071]\n",
      "Mean: 0.8853751015806182\n",
      "Standard Deviation: 0.043477004431628136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "gbrt_optimized_cv_mse_scores = cross_val_score(gbrt_optimized, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "gbrt_optimized_cv_rmse_scores = np.sqrt(abs(gbrt_optimized_cv_mse_scores))\n",
    "gbrt_optimized_cv_r2_scores = cross_val_score(gbrt_optimized, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(gbrt_optimized_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(gbrt_optimized_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this combination of parameters obtained through hyperparameter tuning, the training performance of the Gradient Boosting Regression model has increased significantly. The increase to validation performance has increased marginally, with slight reductions in variance/standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramater Optimization - Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.11103968740973512\n",
      "R-Squared Coefficient: 0.9191192770342501\n",
      "Regularization parameter (alpha): 6.367272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "ridge_optimized = RidgeCV(alphas=np.linspace(start=0.01, stop=10, num=100), cv=10)\n",
    "ridge_optimized.fit(X_train_prepared, y_train_prepared)\n",
    "ridge_optimized_preds = ridge_optimized.predict(X_train_prepared)\n",
    "\n",
    "ridge_optimized_error = np.sqrt(mean_squared_error(y_train_prepared, ridge_optimized_preds))\n",
    "ridge_optimized_r2 = r2_score(y_train_prepared, ridge_optimized_preds)\n",
    "print(f\"Root Mean Squared Error: {ridge_optimized_error}\")\n",
    "print(f\"R-Squared Coefficient: {ridge_optimized_r2}\")\n",
    "print(f\"Regularization parameter (alpha): {ridge_optimized.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.03915932 0.04990561 0.03912958 0.05668971 0.05629608 0.05295406\n",
      " 0.04350696 0.03936525 0.0414996  0.03409737]\n",
      "Mean: 0.045260355289290725\n",
      "Standard Deviation: 0.007645783013186892\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.87779007 0.87226452 0.89859217 0.7976319  0.79591121 0.88630474\n",
      " 0.87527848 0.90226719 0.86725484 0.91950601]\n",
      "Mean: 0.8692801134792203\n",
      "Standard Deviation: 0.03923989584151503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_optimized = Ridge(alpha=5.055454545454545, random_state=42)\n",
    "\n",
    "ridge_optimized_cv_mse_scores = cross_val_score(ridge_optimized, X_train_prepared, y_train_prepared, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "ridge_optimized_cv_rmse_scores = np.sqrt(abs(ridge_optimized_cv_mse_scores))\n",
    "ridge_optimized_cv_r2_scores = cross_val_score(ridge_optimized, X_train_prepared, y_train_prepared, cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(ridge_optimized_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(ridge_optimized_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tuned value of the regularization parameter (alpha), we see marginal decrease in training performance. There is, however, a slight increase to the validation performance and a decrease to its standard deviation/variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramater Optimization - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "param_distributions = {\n",
    "    \"n_estimators\": [100, 500, 1000, 1500, 2000],\n",
    "    \"max_depth\": [1, 2, 3, 4],\n",
    "    \"subsample\": [0.5, 0.75, 1],\n",
    "    \"colsample_bytree\": [0.5, 0.75, 1],\n",
    "    \"reg_alpha\": np.linspace(start=0.01, stop=10, num=100),\n",
    "    \"reg_lambda\": np.linspace(start=0.01, stop=10, num=100),\n",
    "    \"gamma\": np.linspace(start=0.01, stop=10, num=100)\n",
    "}\n",
    "xgb_reg = RandomizedSearchCV(xgb, param_distributions=param_distributions, n_iter=500, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, random_state=42)\n",
    "xgb_search = xgb_reg.fit(X_train_prepared, y_train_prepared.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative RMSE: -0.09642469280211605\n",
      "Parameters for the best estimator: \n",
      "{'subsample': 0.75, 'reg_lambda': 5.156363636363636, 'reg_alpha': 1.5236363636363637, 'n_estimators': 100, 'max_depth': 3, 'gamma': 0.01, 'colsample_bytree': 0.75}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Negative RMSE: {xgb_search.score(X_train_prepared, y_train_prepared.flatten())}\")\n",
    "print(f\"Parameters for the best estimator: \\n{xgb_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 316)\n",
      "(1168, 1)\n",
      "(292, 316)\n",
      "(292, 1)\n",
      "Root Mean Squared Error: 0.09642469280211605\n",
      "R-Squared Coefficient: 0.9390090930561361\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(y_train_prepared.shape)\n",
    "print(X_test_prepared.shape)\n",
    "print(y_test_prepared.shape)\n",
    "\n",
    "xgb_reg_optimized = XGBRegressor(\n",
    "    random_state=42,\n",
    "    colsample_bytree=0.75,\n",
    "    gamma=0.01,\n",
    "    max_depth=3,\n",
    "    n_estimators=100,\n",
    "    reg_alpha=1.5236363636363637,\n",
    "    reg_lambda=5.156363636363636,\n",
    "    subsample=0.75\n",
    ")\n",
    "xgb_reg_optimized.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "xgb_reg_optimized_preds = xgb_reg.predict(X_train_prepared)\n",
    "\n",
    "xgb_reg_optimized_error = np.sqrt(mean_squared_error(y_train_prepared.flatten(), xgb_reg_optimized_preds))\n",
    "xgb_reg_optimized_r2 = r2_score(y_train_prepared.flatten(), xgb_reg_optimized_preds)\n",
    "print(f\"Root Mean Squared Error: {xgb_reg_optimized_error}\")\n",
    "print(f\"R-Squared Coefficient: {xgb_reg_optimized_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.10436418 0.15913883 0.1457126  0.18324052 0.15091409 0.18900752\n",
      " 0.16754806 0.12605592 0.11359456 0.11464463]\n",
      "Mean: 0.14542208974450363\n",
      "Standard Deviation: 0.028388239989789992\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.90735082 0.86136668 0.84990796 0.7743273  0.84346018 0.84540176\n",
      " 0.80257359 0.89303462 0.89384309 0.90287489]\n",
      "Mean: 0.8574140891935829\n",
      "Standard Deviation: 0.0418068440109111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "xgb_reg_optimized_cv_mse_scores = cross_val_score(xgb_reg_optimized, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "xgb_reg_optimized_cv_rmse_scores = np.sqrt(abs(xgb_reg_optimized_cv_mse_scores))\n",
    "xgb_reg_optimized_cv_r2_scores = cross_val_score(xgb_reg_optimized, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(xgb_reg_optimized_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(xgb_reg_optimized_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitted with the above combination of parameters found via RandomSearchCV, both the training and validation performance has decreased. The standard deviation/variance has also increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions based of hyperparameter tuning of candidate models\n",
    "\n",
    "- Based on the results of the hyperparameter optimized candidate models, the Gradient Boosting Regression model still maintains the highest performance in terms of the training set and validation set even though it has overfitted more than the other two candidate models. By fitting the model with the tuned hyperparameters, the variance of the Gradient Boosting Regression model had also decreased from the initial model fit prior to hyperparameter tuning.\n",
    "\n",
    "- Tuning the Regularization parameter of the Ridge Regression model saw little changes to their performance. However, their variances were observed to decrease as a result of using tuned Regularization parameters.\n",
    "\n",
    "- A combination of hyperparameters that would improve the existing XGBoost model could not be found with RandomSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development - Further Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Regression with top candidate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.04586960141138212\n",
      "R-Squared Coefficient: 0.9861981120852197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "gbrt_reg = GradientBoostingRegressor(\n",
    "    random_state=42, \n",
    "    learning_rate=0.06810390304059954, \n",
    "    max_depth=3,\n",
    "    max_leaf_nodes=10, \n",
    "    n_estimators=1000,\n",
    "    subsample=0.8112174950633936\n",
    ")\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "ridge_reg = Ridge(alpha=5.055454545454545, random_state=42)\n",
    "\n",
    "voting_reg = VotingRegressor(\n",
    "    estimators=[\n",
    "        (\"gbrt\", gbrt_reg),\n",
    "        (\"xgb\", xgb_reg),\n",
    "        (\"ridge\", ridge_reg)\n",
    "    ],\n",
    "    n_jobs=-1\n",
    ")\n",
    "voting_reg.fit(X_train_prepared, y_train_prepared.flatten())\n",
    "voting_reg_preds = voting_reg.predict(X_train_prepared)\n",
    "\n",
    "voting_reg_error = np.sqrt(mean_squared_error(y_train_prepared.flatten(), voting_reg_preds))\n",
    "voting_reg_r2 = r2_score(y_train_prepared.flatten(), voting_reg_preds)\n",
    "print(f\"Root Mean Squared Error: {voting_reg_error}\")\n",
    "print(f\"R-Squared Coefficient: {voting_reg_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores and Statistics for RMSE:\n",
      "\n",
      "Scores: [0.09699093 0.14978879 0.11752215 0.17191779 0.12975768 0.16218745\n",
      " 0.11998173 0.10904191 0.11665891 0.09170372]\n",
      "Mean: 0.12655510595144356\n",
      "Standard Deviation: 0.025486482278121732\n",
      "\n",
      "\n",
      "CV Scores and Statistics for R-Squared Coefficient:\n",
      "\n",
      "Scores: [0.91997956 0.87717864 0.90236559 0.80135499 0.88427388 0.88616368\n",
      " 0.89875894 0.91996063 0.88803841 0.93785617]\n",
      "Mean: 0.8915930490503495\n",
      "Standard Deviation: 0.03516326743991818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "voting_reg_cv_mse_scores = cross_val_score(voting_reg, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"neg_mean_squared_error\")\n",
    "voting_reg_cv_rmse_scores = np.sqrt(abs(voting_reg_cv_mse_scores))\n",
    "voting_reg_cv_r2_scores = cross_val_score(voting_reg, X_train_prepared, y_train_prepared.flatten(), cv=10, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Scores and Statistics for RMSE:\\n\")\n",
    "display_cv_scores(voting_reg_cv_rmse_scores)\n",
    "print(\"\\n\")\n",
    "print(\"CV Scores and Statistics for R-Squared Coefficient:\\n\")\n",
    "display_cv_scores(voting_reg_cv_r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A voting ensemble model combining the tuned candidate models seems to have slightly better performance than the individual respective candidate models and has the lowest standard deviation/variance out of all the models that make up the Voting Regressor. However, interpreting which features are the most important becomes harder with using this ensemble model, i.e. no simple way of getting feature weights or feature importances by using estimator's attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development - Overall Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of overall performance, the Voting Regression model that combines the hyperparameter-tuned candidate models scores the highest in terms of R-Squared Coefficient and its variance/standard deviation remains similar to that of the individual models it consists of.\n",
    "\n",
    "- Though it scales more poorly in computational complexity compared to Ridge Regression model, the Gradient Boosting Regression model offers the best performance and still has a way to output which features are \"important\" to predicting house sale price. It is also less strict in its assumptions about the data's behaviour and relationships. Ridge Regression still follows the typical assumptions for Linear Regression, i.e. constant variance, normally distributed residuals, linear relationships between the dependent and indepdent variables, independent and identically distributed data, etc.\n",
    "\n",
    "- The candidate model that will most likely scale the best in terms of computational complexity with decent prediction performance (although less than the Gradient Boosting Regression and Voting Regression models) is the Ridge Regression model. \n",
    "\n",
    "### Model to deploy - Gradient Boosting Regression model\n",
    "\n",
    "- The chosen model to deploy in the web service to be built is the Gradient Boosting Regression model. \n",
    "- It has performance only marginally less than the Voting Regression model but still has some interetability in terms of determining which features are important in predicting house sale price and assumes less about the input features' behaviour.\n",
    "- Once houses are built, their main features are unlikely to change regardless of how many times it is sold. For example, a house built with 2 bathrooms, 4 bedrooms and a garage is likely to retain them for a very long time, and the chances of the house losing one of them is quite low. In addition to this, houses and properties take a long time to be built and sold. This means, we are unlikely to see much drift in terms of the feature data's behaviour, relationships and distributions, so it is a reasonable assumption that we would not have to retrain and redeploy the model very frequently. \n",
    "\n",
    "### Model to use for Kaggle submission - Voting Regression Model\n",
    "\n",
    "- The Voting Regression model will be used for the Kaggle competition submission as it provides the best performance (highest R-Squared Coefficient) out of all the models that were trained during model development with similar variance/standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untransformed training set predictions:\n",
      "[138359.24832127 181792.86813025  87389.67938757 ... 121105.83736849\n",
      " 170549.66016812 190112.30618507]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_kaggle_submission(ids: np.ndarray, preds: np.ndarray, csv_path: str):\n",
    "    \"\"\" Create a csv file containing the predictions of the test set data for kaggle submission.\n",
    "\n",
    "    Args:\n",
    "        ids (numpy.ndarray): An array-like object containing the record IDs of each record in the test data set for Kaggle.\n",
    "\n",
    "        preds (numpy.ndarray): An array-like object containing the predictions of the test data set for Kaggle.\n",
    "\n",
    "        csv_path (string): The path in which to save the Kaggle submission csv file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    preds_df = pd.DataFrame(\n",
    "        data={\n",
    "            \"Id\": ids,\n",
    "            \"SalePrice\": preds\n",
    "        }\n",
    "    )\n",
    "    preds_df.set_index(\"Id\", inplace=True)\n",
    "    preds_df.to_csv(csv_path)\n",
    "\n",
    "def prepare_test_set_data(test_set: pd.DataFrame, categorical_attributes, continuous_attributes):\n",
    "    \"\"\" Apply feature transformations, engineering and scaling to the test set for kaggle submission.\n",
    "\n",
    "    Args:\n",
    "        test_set (pandas.DataFrame): The dataframe containing the test data set for kaggle submission.\n",
    "\n",
    "        categorical_attributes: An array-like object containing the names of the desired categorical attributes.\n",
    "\n",
    "        continuous attributes: An array-like object containing the names of the desired continuous attributes.\n",
    "\n",
    "    Returns:\n",
    "        X_prepared (pandas.DataFrame): A dataframe containing the test set after applying feature transformation, scaling and engineering.\n",
    "    \"\"\"\n",
    "    X_partially_prepared = replace_na_with_none(test_set, categorical_attributes)\n",
    "    X_partially_prepared = createHasBsmtFullBath(X_partially_prepared)\n",
    "    X_partially_prepared = createHasHalfBath(X_partially_prepared)\n",
    "    X_partially_prepared = log_transform_features(X_partially_prepared, continuous_attributes)\n",
    "    X_prepared = full_pipeline.transform(X_partially_prepared)\n",
    "\n",
    "    return X_prepared\n",
    "\n",
    "def invert_min_max_norm(x: np.ndarray, lower: float, upper: float):\n",
    "    \"\"\" Invert min-max normalization performed on the given input numpy array object.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): A nnmpy array containing the values that were transformed via min-max normalization.\n",
    "\n",
    "        lower (float): The lower bound used for the min-max normalization of x.\n",
    "        \n",
    "        upper (float): The upper bound used for the min-max normalization of x.\n",
    "\n",
    "    Returns:\n",
    "        x_inverse (ndarray): A numpy array containing the values from the result of applying an inverse min-max normalization operation on the input array.\n",
    "    \"\"\"\n",
    "    x_inverse = x * (upper - lower) + lower\n",
    "\n",
    "    return x_inverse\n",
    "\n",
    "a = np.min(y_train)\n",
    "b = np.max(y_train)\n",
    "log_preds = invert_min_max_norm(voting_reg_preds, lower=a, upper=b)\n",
    "preds = np.exp(log_preds) - 0.001\n",
    "print(f\"Untransformed training set predictions:\\n{preds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
      "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
      "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
      "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
      "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
      "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
      "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
      "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
      "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
      "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
      "\n",
      "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0       0      6    2010        WD         Normal  \n",
      "1   12500      6    2010        WD         Normal  \n",
      "2       0      3    2010        WD         Normal  \n",
      "3       0      6    2010        WD         Normal  \n",
      "4       0      1    2010        WD         Normal  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "HOUSING_TESTING_DATA_PATH = os.path.join(\"data\", \"test.csv\")\n",
    "housing_test_data = load_csv_data(csv_path=HOUSING_TESTING_DATA_PATH)\n",
    "\n",
    "print(housing_test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 316)\n"
     ]
    }
   ],
   "source": [
    "X_test_kaggle = prepare_test_set_data(housing_test_data, categorical_features, continuous_features)\n",
    "\n",
    "print(X_test_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459,)\n",
      "Untransformed test set predictions:\n",
      "[120554.24755041 150418.52432758 182732.49248091 ... 149753.13629367\n",
      " 114591.49603669 220295.391393  ]\n",
      "(1459,)\n"
     ]
    }
   ],
   "source": [
    "voting_reg_preds_kaggle = voting_reg.predict(X_test_kaggle)\n",
    "print(voting_reg_preds_kaggle.shape)\n",
    "\n",
    "a = np.min(y_train)\n",
    "b = np.max(y_train)\n",
    "log_preds = invert_min_max_norm(voting_reg_preds_kaggle, lower=a, upper=b)\n",
    "preds = np.exp(log_preds) - 0.001\n",
    "print(f\"Untransformed test set predictions:\\n{preds}\")\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_SUBMISSION_FILEPATH = os.path.join(\"data\", \"submission.csv\")\n",
    "ids = housing_test_data[\"Id\"].to_numpy()\n",
    "\n",
    "create_kaggle_submission(ids, preds, KAGGLE_SUBMISSION_FILEPATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ames_housing_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e7cb4bb7c503a87b08cc4912e3f18041ba300cf13020f9adf04a3d56f8dd58a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
